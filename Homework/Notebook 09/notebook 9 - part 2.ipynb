{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "F4j7JQIc11MT"
            },
            "source": [
                "# SQL: Advanced Topics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction and Table of Contents"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "WLXObLfg1Rc9",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "Thus far, we have kept our discussion of what SQL actually *is* relatively brief. This has been intentional; our goal has been to get you comfortable writing SQL queries as quickly as possible so that you can use it where necessary.\n",
                "\n",
                "In this section, we will take a moment to talk about SQL more generally and explore some more advanced topics. We will:\n",
                "\n",
                "- Talk about databases as software, discuss SQL's formal syntax, and compare SQL with other tools.\n",
                "- Spend some time reviewing more advanced SQL functionality, such as common-table expressions (CTEs) and window functions.\n",
                "- Review some of the security implications related to working with SQL and revisit the concept of placeholder bindings.\n",
                "\n",
                "We will end this section by showcasing how you can use some of these tools to answer a frequently-asked but deceptively tricky data analysis question: the \"top-n cases by group\" problem."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "- [SQL, SQLite, and Comparisons with Other Tools](#SQL,-SQLite,-and-Comparisons-with-Other-Tools)\n",
                "    - [Why SQL?](#Why-SQL?)\n",
                "    - [SQLite vs. Other RDBMSs](#SQLite-vs.-Other-RDBMSs)\n",
                "    - [The Structure of a `SELECT` Statement](#The-Structure-of-a-SELECT-Statement)\n",
                "    - [Data Transformations in SQL vs. Pandas](#Data-Transformations-in-SQL-vs.-Pandas)\n",
                "- [Advanced Functionality](#Advanced-Functionality)\n",
                "    - [Dataset Overview: The NYC Jobs Postings Database](#Dataset-Overview:-The-NYC-Jobs-Postings-Database)\n",
                "    - [Introduction to SQLite String Manipulation](#Introduction-to-SQLite-String-Manipulation)\n",
                "    - [Introduction to Recoding Variables with CASE Statements in SQLite](#Introduction-to-Recoding-Variables-with-CASE-Statements-in-SQLite)\n",
                "    - [Introduction to Inline Subqueries and Common Table Expressions (CTEs)](#Introduction-to-Inline-Subqueries-and-Common-Table-Expressions-(CTEs))\n",
                "    - [Introduction to Window Functions](#Introduction-to-Window-Functions)\n",
                "    - [Handling NULL Values](#Handling-NULL-Values)\n",
                "- [Security Implications and Placeholder Bindings](#Security-Implications-and-Placeholder-Bindings)\n",
                "    - [Queries and User Input](#Queries-and-User-Input)\n",
                "    - [SQL Injection Attacks](#SQL-Injection-Attacks)\n",
                "    - [Protecting Against SQL Injections](#Protecting-Against-SQL-Injections)\n",
                "- [An Applied Example: Finding the Top N Cases per Group](#An-Applied-Example:-Finding-the-Top-N-Cases-per-Group)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "PsJixO8V1KFj",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "## SQL, SQLite, and Comparisons with Other Tools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "sswviJVZ8ioh",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "In this section, we will spend some time talking about what databases and SQL actually are. We will then take a moment to compare SQL with other similar tools.\n",
                "\n",
                "**If you are already intimately familiar with the landscape of modern database offerings, you may be able to skip this section.** However, if you enjoy taking a step back to see the big picture, then this section is for you."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "tGYGGilm1NNC"
            },
            "source": [
                "\n",
                "### Why SQL?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rlypoMBZ8934"
            },
            "source": [
                "Some of you have probably been wondering: \"Why do we even *need* SQL? Can't we do most of this work with other tools that we have already seen, like [Pandas](https:\/\/pandas.pydata.org\/)?\" To answer this question, it may be worth taking a moment to discuss what a database management system actually *is*.\n",
                "\n",
                "There are many ways to digitally store information. However, managing this information manually can be surprisingly difficult. As the amount of information increases in scale, the task of storing it efficiently and correctly can substantially grow in complexity. It would be useful if we had some dedicated tool for managing our collection of information, or *database*.\n",
                "\n",
                "This is where *database management systems*, or DBMSs, can become useful. In their textbook, *Fundamentals of Database Systems*, Elmasri and Navathe define a DBMS as \"a computerized system that enables users to create and maintain a database.\" DBMSs can provide us with desirable features and abstract away complex data storage tasks which we would otherwise need to handle ourselves.\n",
                "\n",
                "> For example, DBMSs can make it possible for multiple users to simultaneously update a database, track metadata, and handle the storage of the data files on a hard drive. Tools like Pandas and NumPy, while extremely useful, exist to solve different problems.\n",
                "\n",
                "![](resource\/asnlib\/publicdata\/DBMS.png)\n",
                "\n",
                "There are many different types of DBMSs but those which organize their data into *tables* are usually *relational database management systems*, or RDBMSs.\n",
                "\n",
                "> Technically, an RDBMS is a database management system which implements the [relational model](https:\/\/en.wikipedia.org\/wiki\/Relational_model). This is a more technical concept which we will not explore here, but those of you who wish to dig deeper may find the topic's Wikipedia article enlightening. For an even more in-depth discussion, see \"Chapter 5: The Relational Data Model and SQL\" in *Fundamentals of Database Systems*, by Ramez Elmasri and Shamkant B. Navathe (7th Edition).\n",
                "\n",
                "[SQLite](https:\/\/www.sqlite.org\/index.html), which you used in the previous parts of this notebook, is an example of an RDBMS. Generally, SQL is the language used by RDBMSs to define, query, and update the data they are managing.\n",
                "\n",
                "> Specifically, you have been using Python to execute SQL calls. You could, however, use other languages like C or Java to execute SQL calls with SQLite (or use SQLite directly, without any other language). In fact, you could have multiple programs written in different languages interacting with *the same database* by using a DBMS and SQL. If you have never considered this before, we encourage you to pause and take a moment to reflect on the implications of being able to do this!\n",
                "\n",
                "So, to summarize: an RDBMS helps us handle the complex task of managing a database, and we use SQL to interact with the RDBMS."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "EXs9rMtUG_TI"
            },
            "source": [
                "### SQLite vs. Other RDBMSs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3mMrmc23RYXA"
            },
            "source": [
                "In this class, you have been using Python's [SQLite3](https:\/\/docs.python.org\/3\/library\/sqlite3.html#) module to interact with databases managed by [SQLite](https:\/\/www.sqlite.org\/about.html). We briefly introduced SQLite in the earlier sections of this lesson. Now, we will take a moment to compare SQLite with other RDBMSs you might have to work with in the real world.\n",
                "\n",
                "There are several SQLite-specific details which make it distinct from other RDBMSs you might find yourself working with:\n",
                "\n",
                "- [SQLite is *self-contained*](https:\/\/www.sqlite.org\/selfcontained.html): it has very few dependencies and can run on any operating system, including embedded operating systems. The entire library is contained in a single source file.\n",
                "- [SQLite is *serverless*](https:\/\/www.sqlite.org\/serverless.html): processes which access the database read and write directly from disk. Most database engines, by contrast, tend to implement a client-server model; there will be a separate server process which recieves requests from clients (often via TCP\/IP requests) and the server will decide what to do with those requests.\n",
                "- [SQLite is *zero-configuration*](https:\/\/www.sqlite.org\/zeroconf.html): users do not need to run a setup procedure, assign access permissions, or manage configuration files.\n",
                "\n",
                "These features make SQLite an excellent option for developers who want a small, fast, and local database solution. Consequently, [SQLite is the most widely deployed database engine in the world](https:\/\/www.sqlite.org\/mostdeployed.html). However, there are many other great RDBMSs out there which you might need to use at some point! For reference, we have put together a table highlighting some of the differences you might encounter in other RDBMSs outside of this course.\n",
                "\n",
                "\n",
                "| Engine               | Client-Server | Free              | License              | Python API             |\n",
                "|----------------------|---------------|-------------------|----------------------|------------------------|\n",
                "| SQLite               | No            | Yes               | Public domain        | sqlite3                |\n",
                "| Oracle               | Yes           | Edition Dependent | Proprietary          | Python-oracledb        |\n",
                "| Microsoft SQL Server | Yes           | Edition Dependent | Proprietary          | pyodbc, or pymssql     |\n",
                "| PostgreSQL           | Yes           | Yes               | Open Source          | psycopg3               |\n",
                "| MySQL                | Yes           | Yes               | GPLv2 or Proprietary | mysql-connector-python |\n",
                "\n",
                "[SQLite's documentation](https:\/\/www.sqlite.org\/whentouse.html) outlines some of its ideal use-cases, alongside instances when another tool may be a better fit."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rigDf-cBcvYi"
            },
            "source": [
                "\n",
                "### The Structure of a `SELECT` Statement"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "N3mbobv4cxUu"
            },
            "source": [
                "Despite the fact that SQL exists as an ISO standard, many SQL engine implement non-standard versions of SQL. Even SQLite implements a [slightly non-standard](https:\/\/www.sqlite.org\/omitted.html) variant of the SQL standard. However, the general structure of SQL queries will tend to be the same across various SQL dialects. In this section, we will quickly review the structure of a `SELECT` statement and provide resources for you to use when writing your own queries.\n",
                "\n",
                "SQLite recognizes [many kinds](https:\/\/www.sqlite.org\/lang.html) of statements (for example, we briefly covered `INSERT` statements in the earlier sections of this lesson). `SELECT` statements can become rather complicated, so it is worth reviewing the structure of precisely what terms can be involved with them. Specifically, components of a `SELECT` statement will *always follow this order*:\n",
                "\n",
                "1. `SELECT result-columns`\n",
                "2. `FROM table-or-subquery`\n",
                "3. `WHERE expr`\n",
                "4. `GROUP BY expr` (and possibly `HAVING`)\n",
                "5. `WINDOW window-def`\n",
                "\n",
                "This is sometimes called the \"`SELECT` core.\" In addition, we can add `WITH` expressions before the query, and `ORDER BY` and `LIMIT` terms to the end of the query.\n",
                "\n",
                "> We will discuss the use of the `WITH` and `WINDOW` terms later in this notebook.\n",
                "\n",
                "SQLite defines [the syntax of a valid SELECT statment in their documentation](https:\/\/www.sqlite.org\/lang_select.html), which is displayed as a helpful flow-chart. This can be useful for debugging purposes. However, most queries can be constructed by following this process:\n",
                "\n",
                "1. Determine what source data is required and build the table-expression for the `FROM` statement.\n",
                "2. Filter the table with the `WHERE` statement.\n",
                "3. `SELECT` the desired variables, optionally aggregating the results by using the `GROUP BY` term.\n",
                "4. Order and limit the results with the `ORDER BY` and `LIMIT` terms."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "r7KAdbn7re6g"
            },
            "source": [
                "### Data Transformations in SQL vs. Pandas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "QCL1QPhZrfu9"
            },
            "source": [
                "You have likely realized that we can perform many of the same operations on tables represented in Pandas or housed in a SQL database. For example, the concept of filtering a table by evaluting some conditional expression can be accomplished by using a `WHERE` clause or [boolean indexing in Pandas](https:\/\/pandas.pydata.org\/docs\/user_guide\/indexing.html#boolean-indexing).\n",
                "\n",
                "It may be useful to know that Pandas has compiled a [helpful reference](https:\/\/pandas.pydata.org\/docs\/getting_started\/comparison\/comparison_with_sql.html) of how to accomplish common SQL tasks in Pandas. We encourage you to refer to it if you find one of these tools more intuitive than the other."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "V_55wObGtMtU",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "## Advanced Functionality"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "2Hljr8setOpO"
            },
            "source": [
                "In this section, we will expand our understanding of what is possible within an SQL query. While some of these concepts are more complicated than what we have discussed thus far, these tools can be extremely powerful in the proper circumstances.  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Gue8HDXuIp0X",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "### Dataset Overview: The NYC Jobs Postings Database\n",
                "\n",
                "This dataset is a normalized version of the NYC Jobs Postings data. It is available on [NYC OpenData](https:\/\/opendata.cityofnewyork.us\/), which is a platform for free public data published by New York City agencies and other partners. The original dataset was retreived on 08-30-2024. The most current version of the dataset can be found [here](https:\/\/data.cityofnewyork.us\/City-Government\/Jobs-NYC-Postings\/kpav-sd4t\/about_data).\n",
                "\n",
                "The data contains information on current job postings available on the City of New York's official jobs site. It includes both internal postings for city employees and external postings available to the general public.\n",
                "\n",
                "The dataset has been normalized and loaded into a SQLite database `nyc_jobs.db` to enable reteival with SQL. Below is a list of the tables included in the database along with a brief description of each:\n",
                "\n",
                "- **job_post**: Contains core information about each job posting, such as the job ID, title, posting date, and the date the posting expires (post_until). This is the central table linking to other detailed tables.\n",
                "  \n",
                "- **agency**: Stores details about the agencies responsible for the job postings, including the agency ID and agency name.\n",
                "  \n",
                "- **job_title**: Provides detailed information on the job titles listed in the postings, including the title classification and civil service title.\n",
                "\n",
                "- **salary**: Contains salary information for the job postings, such as the salary range and salary frequency (e.g., annual, hourly).\n",
                "\n",
                "- **location**: Details the locations associated with the job postings, including the specific work location and any relevant divisions or units.\n",
                "\n",
                "**IMPORTANT!** Please run the cells below to properly configure your notebook environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "main.global_imports"
                ]
            },
            "outputs": [],
            "source": [
                "### Global imports\n",
                "import dill\n",
                "from cse6040_devkit import plugins, utils\n",
                "\n",
                "utils.add_from_file('sql_validator', plugins)\n",
                "utils.add_from_file('malicious_executor', plugins)\n",
                "utils.add_from_file('safe_executor', plugins)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import sqlite3\n",
                "import pandas as pd\n",
                "\n",
                "# Path to the SQLite database file; change as needed\n",
                "db = 'resource\/asnlib\/publicdata\/nyc_jobs.db'\n",
                "# Database connection\n",
                "conn = sqlite3.connect(db)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "get_database_schema__FREE.prompt"
                ]
            },
            "source": [
                "### Exercise 0: (0 points)\n",
                "**get_database_schema__FREE**  \n",
                "\n",
                "**Example:** we have defined `get_database_schema__FREE` as follows:\n",
                "\n",
                "**This is a free exercise!** \n",
                "\n",
                "    **Please run the test cell below to collect your FREE point!**\n",
                "\n",
                "    The output will show the structure of the database which we will use for the following exercises.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "get_database_schema__FREE.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 0  \n",
                "def get_database_schema__FREE(conn):\n",
                "    # Retrieve the list of tables from sqlite_master\n",
                "    tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
                "    tables = pd.read_sql_query(tables_query, conn)\n",
                "\n",
                "    # Prepare DataFrame to hold combined results\n",
                "    schema_info = pd.DataFrame()\n",
                "\n",
                "    # Loop through tables to get column details\n",
                "    for table in tables['name']:\n",
                "        # Get column details\n",
                "        pragma_table_info = f\"PRAGMA table_info('{table}')\"\n",
                "        table_info = pd.read_sql_query(pragma_table_info, conn)\n",
                "        table_info['table_name'] = table  # Add table name to the DataFrame\n",
                "\n",
                "        # Add to main DataFrame\n",
                "        schema_info = pd.concat([schema_info, table_info], ignore_index=True)\n",
                "\n",
                "    # Select and rename relevant columns\n",
                "    schema_info = schema_info[['table_name', 'name', 'type']]\n",
                "    schema_info.columns = ['table', 'column', 'type']\n",
                "\n",
                "    return schema_info\n",
                "\n",
                "### Demo function call\n",
                "df_schema = get_database_schema__FREE(conn)\n",
                "display(df_schema)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "get_database_schema__FREE.test_boilerplate"
                ]
            },
            "source": [
                " \n",
                " <!-- Test Cell Boilerplate -->  \n",
                " The test cell below will always pass. Please submit to collect your free points for get_database_schema__FREE (exercise 0).\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_0",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "get_database_schema__FREE.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 0  \n",
                "\n",
                "\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "EkguQc74lD0b",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "### Introduction to SQLite String Manipulation\n",
                "\n",
                "By now, you should be familiar with Python's ability to process and manipulate textual data. Here, we will discuss SQLite and its limitations when dealing with strings, particularly when compared to more powerful tools like Python and enterprise-grade relational databases like Oracle and SQL Server.\n",
                "\n",
                "SQLite offers a basic set of string functions, which can make complex string operations challenging. Notably, SQLite lacks:\n",
                "- Built-in support for regular expressions\n",
                "- Advanced string to datetime parsing functionailty\n",
                "\n",
                "These limitations can force you to implement more creative solutions, often involving combinations of functions like `TRIM`, `SUBSTR`, `INSTR`, and `REPLACE` to achieve results that would be straightforward in other environments. The following exercise will ask you to get creative within these constraints while extracting meaningful data from the NYC Jobs database."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "parse_classification.prompt"
                ]
            },
            "source": [
                "### Exercise 1: (0 points)\n",
                "**parse_classification**  \n",
                "\n",
                "**Your task:** define `parse_classification` as follows:\n",
                "\n",
                "**Activity**: Extract and Separate Title Classification Code and Description\n",
                "\n",
                "**Inputs**: None\n",
                "\n",
                "**Return**: `query`: a Python string containing a SQLite query. It should query the database to create a new DataFrame from the `job_title` table with the following columns:\n",
                "- `title_classification`: The original `title_classification` column from the `job_title` table.\n",
                "- `title_classification_desc`: The text portion of the `title_classification` with the final dash and integer removed.\n",
                "- `title_classification_code`: The integer portion of the `title_classification` after the last dash.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- The database table you will need is named `job_title`.\n",
                "- The column you will work with is `title_classification`.\n",
                "\n",
                "**Hint**: There are multiple ways to solve this exercise. The following SQLite functions may help, but not all are strictly necessary, [SUBSTR](https:\/\/www.sqlite.org\/lang_corefunc.html#substr), [INSTR](https:\/\/www.sqlite.org\/lang_corefunc.html#instr), and [REPLACE](https:\/\/sqlite.org\/lang_corefunc.html#replace).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parse_classification.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 0  \n",
                "def parse_classification():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "parse_classification_query = parse_classification()\n",
                "parse_classification_df = pd.read_sql_query(parse_classification_query, conn)\n",
                "display(parse_classification_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "parse_classification.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "\n",
                "| title_classification   | title_classification_desc   |   title_classification_code |\n",
                "|:-----------------------|:----------------------------|----------------------------:|\n",
                "| Competitive-1          | Competitive                 |                           1 |\n",
                "| Non-Competitive-5      | Non-Competitive             |                           5 |\n",
                "| Non-Competitive-5      | Non-Competitive             |                           5 |\n",
                "| Competitive-1          | Competitive                 |                           1 |\n",
                "| Competitive-1          | Competitive                 |                           1 |\n",
                "\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for parse_classification (exercise 1). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_1",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "parse_classification.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 0  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_executor(parse_classification),\n",
                "              ex_name='parse_classification',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to parse_classification did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "R4peB8OBu4oa",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "### Introduction to Recoding Variables with CASE Statements in SQLite\n",
                "\n",
                "In SQLite, the `CASE` statement is a powerful tool that allows you to recode variables based on specific conditions. It works similarly to an `IF-THEN-ELSE` structure in programming languages. By using `CASE`, you can create new columns, transform existing values, or recategorize data based on conditional logic directly within your SQL queries.\n",
                "\n",
                "#### Example Case Statement\n",
                "\n",
                "Suppose you have a table called `employees` with a column named `experience_level` that categorizes employees as `'Junior'`, `'Mid'`, or `'Senior'`. You want to create a new column called `salary_band` that assigns a salary band based on the `experience_level`. Here\u2019s a simple example:\n",
                "\n",
                "```sql\n",
                "SELECT\n",
                "    employee_id,\n",
                "    experience_level,\n",
                "    CASE\n",
                "        WHEN experience_level = 'Junior' THEN 'Low'\n",
                "        WHEN experience_level = 'Mid' THEN 'Medium'\n",
                "        WHEN experience_level = 'Senior' THEN 'High'\n",
                "        ELSE 'Unknown'\n",
                "    END AS salary_band\n",
                "FROM\n",
                "    employees;\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "convert_post_until.prompt"
                ]
            },
            "source": [
                "### Exercise 2: (0 points)\n",
                "**convert_post_until**  \n",
                "\n",
                "**Your task:** define `convert_post_until` as follows:\n",
                "\n",
                "**Activity**: Convert Date Strings in the `post_until` Column to Standard Date Format\n",
                "\n",
                "**Objective**: Write a SQLite query that converts the date strings in the `post_until` column from the `job_post` table into the standardized `YYYY-MM-DD` format.\n",
                "\n",
                "**Return**: `query` \u2014 a Python string containing the SQLite query that generates a DataFrame with the following columns:\n",
                "- `post_until`: The original date string from the `job_post` table.\n",
                "- `post_until_converted`: The converted date string in `YYYY-MM-DD` format.\n",
                "\n",
                "**Steps**:\n",
                "- You will be working with the `job_post` table.\n",
                "- The `post_until` column contains date strings in the `DD-MMM-YYYY` format (e.g., `24-AUG-2024`).\n",
                "- Convert these date strings to the `YYYY-MM-DD` format (e.g., `2024-08-24`).\n",
                "\n",
                "**Hints**:\n",
                "- There are two potential approaches:\n",
                "  1. Manually construct a `CASE` statement using SQLite functions like [PRINTF](https:\/\/www.sqlite.org\/printf.html) and [STRFTIME](https:\/\/www.sqlite.org\/lang_datefunc.html#strftime).\n",
                "  2. Dynamically generate the `CASE` statement in Python using `f-strings` and `join`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "convert_post_until.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 2  \n",
                "def convert_post_until():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "convert_post_until_query = convert_post_until()\n",
                "convert_post_until_df = pd.read_sql_query(convert_post_until_query, conn)\n",
                "display(convert_post_until_df[convert_post_until_df['post_until'].notnull()].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "convert_post_until.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "\n",
                "| post_until   | post_until_converted   |\n",
                "|:-------------|:-----------------------|\n",
                "| 25-AUG-2024  | 2024-08-25             |\n",
                "| 24-AUG-2024  | 2024-08-24             |\n",
                "| 12-JUN-2025  | 2025-06-12             |\n",
                "| 05-SEP-2024  | 2024-09-05             |\n",
                "| 25-SEP-2024  | 2024-09-25             |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for convert_post_until (exercise 2). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_2",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "convert_post_until.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 2  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_executor(convert_post_until),\n",
                "              ex_name='convert_post_until',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to convert_post_until did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "LZNZPVJPzJqE",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "### Introduction to Inline Subqueries and Common Table Expressions (CTEs)\n",
                "\n",
                "When working with SQL, it's common to encounter situations where you need to perform calculations or data transformations based on grouped or filtered data. Two powerful tools for handling such scenarios are **inline subqueries** and **Common Table Expressions (CTEs)**. Both approaches allow you to structure your queries in a way that breaks down complex operations into manageable steps, but they do so in slightly different ways.\n",
                "\n",
                "#### Inline Subqueries\n",
                "\n",
                "An **inline subquery** is a query nested within another SQL query, typically within the `SELECT`, `WHERE`, or `FROM` clause. Inline subqueries allow you to perform calculations or filtering within the context of the outer query. They are particularly useful when you need to filter results based on aggregated values like maximum, minimum, or average.\n",
                "\n",
                "**Example**: Suppose you have a table `employees` and you want to compare each employee's salary to the highest salary in their department:\n",
                "\n",
                "```sql\n",
                "SELECT e.name, e.department, e.salary, dept_max.max_salary\n",
                "FROM employees e\n",
                "JOIN (SELECT \n",
                "        department, \n",
                "        MAX(salary) AS max_salary\n",
                "      FROM employees\n",
                "      GROUP BY department) as dept_max ON e.department = dept_max.department;\n",
                "```\n",
                "\n",
                "This query uses an inline subquery to determine the maximum salary for each department. This intermediate result is joined to the `employees` table to attach the max department salary with each employee.\n",
                "\n",
                "Inline subqueries are powerful, but they can become less efficient when the same calculation needs to be repeated multiple times, as each repetition can slow down the query execution. Visit the [w3resource's SQLite Subqueries page](https:\/\/www.w3resource.com\/sqlite\/sqlite-subqueries.php) to learn more.\n",
                "\n",
                "#### Common Table Expressions (CTEs)\n",
                "\n",
                "A **Common Table Expression (CTE)**, introduced by the `WITH` clause, is a named temporary result set that you can reference within your main query. CTEs improve the readability and maintainability of SQL code, especially for complex queries, by allowing you to break down operations into logical steps.\n",
                "\n",
                "**Example**: The same result as the inline subquery example above can be achieved using a CTE:\n",
                "\n",
                "```sql\n",
                "WITH MaxSalaries AS (\n",
                "    SELECT \n",
                "        department, \n",
                "        MAX(salary) AS max_salary\n",
                "    FROM employees\n",
                "    GROUP BY department\n",
                ")\n",
                "SELECT e.name, e.department, e.salary, ms.max_salary\n",
                "FROM employees e\n",
                "JOIN MaxSalaries ms ON e.department = ms.department\n",
                "```\n",
                "\n",
                "This CTE first calculates the maximum salary for each department, then the main query joins this result with the original `employees` table to find the employees with the highest salary in their department.\n",
                "\n",
                "CTEs are often preferred for their clarity and efficiency, particularly when the same calculation or transformation needs to be referenced multiple times within a query. Visit the [SQLite Documentation's CTE page](https:\/\/www.sqlite.org\/lang_with.html) to learn more."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "max_salary_by_category_inline.prompt"
                ]
            },
            "source": [
                "### Exercise 3: (0 points)\n",
                "**max_salary_by_category_inline**  \n",
                "\n",
                "**Your task:** define `max_salary_by_category_inline` as follows:\n",
                "\n",
                "**Activity**: Identify the Maximum Salary for Each Job Category Using an Inline Subquery\n",
                "\n",
                "**Inputs**: None\n",
                "\n",
                "**Return**: `query`: A Python string containing a SQLite query. It should query the database to create a new DataFrame from the `salary`, `job_posting`, and `job_title` tables with the following columns:\n",
                "- `business_title`: The business title from the `job_title` table.\n",
                "- `job_category`: The job category from the `job_title` table.\n",
                "- `salary_range_to`: The maximum salary range for a job posting.\n",
                "- `max_salary`: The maximum salary range for all job postings with the same `job_category`\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- JOIN the `salary`, `job_posting`, and `job_title` tables to correctly match each job posting with its corresponding title, and salary.\n",
                "- Use an inline subquery to determine the maximum salary (`salary_range_to`) for each job category.\n",
                "  - The query must contain an open parenthesis followed by the SELECT keyword.\n",
                "  - The query must not contain the WITH keyword.\n",
                "- The query should use the `DISTINCT` keyword to ensure that there are no duplicate values.\n",
                "\n",
                "**Hint**: The following SQLite functions and concepts will help: [JOIN](https:\/\/www.sqlite.org\/syntax\/join-operator.html), [MAX](https:\/\/www.sqlite.org\/lang_aggfunc.html#max), and [SUBQUERY](https:\/\/www.sqlite.org\/lang_expr.html#subqueries).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "max_salary_by_category_inline.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 3  \n",
                "def max_salary_by_category_inline():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "max_salary_by_category_inline_query = max_salary_by_category_inline()\n",
                "max_salary_by_category_inline_df = pd.read_sql_query(max_salary_by_category_inline_query, conn)\n",
                "display(max_salary_by_category_inline_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "max_salary_by_category_inline.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "\n",
                "| business_title                                   | job_category                                      |   salary_range_to |   max_salary |\n",
                "|:-------------------------------------------------|:--------------------------------------------------|------------------:|-------------:|\n",
                "| SECTION SUPERVISOR                               | Administration & Human Resources                  |           66672.0 |      271736.0 |\n",
                "| SECTION SUPERVISOR                               | Administration & Human Resources                  |           84276.0 |      271736.0 |\n",
                "| Attorney                                         | Administration & Human Resources                  |          108156.0 |      271736.0 |\n",
                "| Clerical Associate IV                            | Administration & Human Resources                  |           68645.0 |      271736.0 |\n",
                "| Senior Customer Service Representative - 644504 | Administration & Human Resources                  |           51796.0 |      271736.0 |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for max_salary_by_category_inline (exercise 3). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_3",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "max_salary_by_category_inline.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 3  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "    plugin_kwargs = utils.load_object_from_publicdata('max_salary_by_category_inline_plugin_kwargs')\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_validator(max_salary_by_category_inline, **plugin_kwargs),\n",
                "              ex_name='max_salary_by_category_inline',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to max_salary_by_category_inline did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "max_salary_by_category_cte.prompt"
                ]
            },
            "source": [
                "### Exercise 4: (0 points)\n",
                "**max_salary_by_category_cte**  \n",
                "\n",
                "**Your task:** define `max_salary_by_category_cte` as follows:\n",
                "\n",
                "**Activity**: Identify the Maximum Salary for Each Job Category Using a query with a CTE.\n",
                "\n",
                "**Inputs**: None\n",
                "\n",
                "**Return**: `query`: A Python string containing a SQLite query. It should query the database to create a new DataFrame from the `salary`, `job_posting`, and `job_title` tables with the following columns:\n",
                "- `job_category`: The job category from the `job_title` table.\n",
                "- `salary_range_to`: The maximum salary range for each job category.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- JOIN the `salary`, `job_posting`, and `job_title` tables to correctly match each job posting with its corresponding title, and salary.\n",
                "- Use a CTE to determine the maximum salary (`salary_range_to`) for each job category.\n",
                "  - The query must contain the `WITH` keyword.\n",
                "- The query should use the `DISTINCT` keyword to ensure that there are no duplicate values.\n",
                "\n",
                "**Hint**: The following SQLite functions and concepts will help: [JOIN](https:\/\/www.sqlite.org\/syntax\/join-operator.html), [MAX](https:\/\/www.sqlite.org\/lang_aggfunc.html#max), and [SUBQUERY](https:\/\/www.sqlite.org\/lang_expr.html#subqueries).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "max_salary_by_category_cte.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 4  \n",
                "def max_salary_by_category_cte():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "max_salary_by_category_cte_query = max_salary_by_category_cte()\n",
                "max_salary_by_category_cte_df = pd.read_sql_query(max_salary_by_category_cte_query, conn)\n",
                "display(max_salary_by_category_cte_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "max_salary_by_category_cte.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "\n",
                "| business_title                                   | job_category                                      |   salary_range_to |   max_salary |\n",
                "|:-------------------------------------------------|:--------------------------------------------------|------------------:|-------------:|\n",
                "| SECTION SUPERVISOR                               | Administration & Human Resources                  |           66672.0 |      271736.0 |\n",
                "| SECTION SUPERVISOR                               | Administration & Human Resources                  |           84276.0 |      271736.0 |\n",
                "| Attorney                                         | Administration & Human Resources                  |          108156.0 |      271736.0 |\n",
                "| Clerical Associate IV                            | Administration & Human Resources                  |           68645.0 |      271736.0 |\n",
                "| Senior Customer Service Representative - 644504 | Administration & Human Resources                  |           51796.0 |      271736.0 |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for max_salary_by_category_cte (exercise 4). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_4",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "max_salary_by_category_cte.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 4  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "    plugin_kwargs = utils.load_object_from_publicdata('max_salary_by_category_cte_plugin_kwargs')\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_validator(max_salary_by_category_cte, **plugin_kwargs),\n",
                "              ex_name='max_salary_by_category_cte',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to max_salary_by_category_cte did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "l5M_aPKoTonh",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "### Introduction to Window Functions\n",
                "\n",
                "Window functions in SQLite provide a way to perform calculations across a set of table rows that are related to the current row. Unlike aggregate functions, which return a single result for a group of rows, window functions can return multiple rows for each row in the group, providing more flexibility in your analysis. Common use cases for window functions include calculating running totals, ranking, and moving averages.\n",
                "\n",
                "Window functions are defined using the `OVER` clause, which specifies the partitioning and ordering of rows within the window. The most commonly used window functions in SQLite include `ROW_NUMBER()`, `RANK()`, and `SUM()`. These functions can be combined with `PARTITION BY` to break the data into subsets and `ORDER BY` to define the sequence in which rows are processed.\n",
                "\n",
                "#### Example of a Window Function\n",
                "\n",
                "Suppose you have a table called `sales` that contains the columns `employee_id`, `sale_date`, and `amount`. You want to calculate the cumulative sales for each employee over time. Here\u2019s a simple example using the `SUM()` window function:\n",
                "\n",
                "```sql\n",
                "SELECT\n",
                "    employee_id,\n",
                "    sale_date,\n",
                "    amount,\n",
                "    SUM(amount) OVER (PARTITION BY employee_id ORDER BY sale_date) AS cumulative_sales\n",
                "FROM\n",
                "    sales\n",
                "ORDER BY\n",
                "    employee_id, sale_date;\n",
                "```\n",
                "\n",
                "In this example:\n",
                "- `SUM(amount)` calculates the running total of `amount`.\n",
                "- The `OVER` clause specifies that the window function should be applied to each `employee_id` individually (`PARTITION BY employee_id`) and should consider the order of `sale_date` (`ORDER BY sale_date`).\n",
                "- The result is a new column, `cumulative_sales`, that shows the cumulative sales amount for each employee over time.\n",
                "\n",
                "Vist the the [SQLite Window Functions Page](https:\/\/www.sqlite.org\/windowfunctions.html) to learn more."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "ranking_postings_by_classification.prompt"
                ]
            },
            "source": [
                "### Exercise 5: (0 points)\n",
                "**ranking_postings_by_classification**  \n",
                "\n",
                "**Your task:** define `ranking_postings_by_classification` as follows:\n",
                "\n",
                "**Activity**: Rank each available job posting within its title classification grouping, ordered by the posting's salary range.\n",
                "\n",
                "**Inputs**: None\n",
                "\n",
                "**Return**: `query`: A Python string containing a SQLite query. It should query the database to create a new DataFrame from the `salary`, `job_posting`, and `job_title` tables with the following columns:\n",
                "- `job_id`: The id from the `job_posting` table.\n",
                "- `title_classification`: The classification for each title in the `job_title` table.\n",
                "- `business_title`: The business title for each title in the `job_title` table.\n",
                "- `posting_updated`: The value for `posting_updated` in the `job_posting` table.\n",
                "- `maximum_salary`: The value for `salary_range_to` in the `salary` table.\n",
                "- `job_rank`: The ranking for each position, as defined below.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- The query should join the `salary`, `job_posting`, and `job_title` tables to correctly match the job categories and their corresponding salaries.\n",
                "- You will need to use the `RANK()` window function to determine the rankings for the jobs.\n",
                "    - You should partition the windows by the posting's title.\n",
                "    - You should order the partitions by:\n",
                "        - The maximum salary (descending)\n",
                "        - The posting update value (descending)\n",
                "        - The job ID (ascending)\n",
                "\n",
                "**Hint**: You will need to use the [OVER](https:\/\/sqlite.org\/windowfunctions.html) keyword to properly define the windows.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "ranking_postings_by_classification.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 5  \n",
                "def ranking_postings_by_classification():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "ranks_by_classification_query = ranking_postings_by_classification()\n",
                "ranks_by_classification_df     = pd.read_sql_query(ranks_by_classification_query, conn)\n",
                "display(ranks_by_classification_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "ranking_postings_by_classification.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "\n",
                "| job_id                                      | title_classification | business_title                                        | posting_updated            |   maximum_salary |   job_rank |\n",
                "|:--------------------------------------------|:---------------------|:------------------------------------------------------|:---------------------------|------------------:|-----------:|\n",
                "| 637954_0be214d1d713426b837b703243b4a706     | Competitive-1         | Director of Engineering, Construction Management...   | 2024-08-14T00:00:00.000    |          235036.0 |          1 |\n",
                "| 637954_1f1800ddb3da459f848a3147ee88d39c     | Competitive-1         | Director of Engineering, Construction Management...   | 2024-08-14T00:00:00.000    |          235036.0 |          2 |\n",
                "| 637954_2966                                 | Competitive-1         | Director of Engineering, Construction Management...   | 2024-08-14T00:00:00.000    |          235036.0 |          3 |\n",
                "| 637954_3e4dfba98f484ada80813347196eedc7     | Competitive-1         | Director of Engineering, Construction Management...   | 2024-08-14T00:00:00.000    |          235036.0 |          4 |\n",
                "| 637954_51c27c951b79409dbdd5aaaaaf88adcd     | Competitive-1         | Director of Engineering, Construction Management...   | 2024-08-14T00:00:00.000    |          235036.0 |          5 |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for ranking_postings_by_classification (exercise 5). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_5",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "ranking_postings_by_classification.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 5  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_executor(ranking_postings_by_classification),\n",
                "              ex_name='ranking_postings_by_classification',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to ranking_postings_by_classification did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "EQZgnKyg1AI3",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "\n",
                "### Handling NULL Values\n",
                "\n",
                "There are two common situations in SQL where you are likely to encounter NULL values:\n",
                "- Some table has an optional field (which is often a sign that the database is not fully [normalized](https:\/\/en.wikipedia.org\/wiki\/Database_normalization)).\n",
                "- You perform a non-inner join, which introduces NULL values.\n",
                "\n",
                "NULL values can cause problems when you attempt to perform certain operations. For example, adding any value to a NULL value will result in another NULL value in SQLite.\n",
                "\n",
                "There are two main tools which SQLite provides for handling default values for NULLs: [`ifnull(X, Y)`](https:\/\/www.sqlite.org\/lang_corefunc.html#ifnull) and [`coalesce(X, Y, ...)`](https:\/\/www.sqlite.org\/lang_corefunc.html#coalesce). Both make it possible to provide default values for NULL instances. `coalesce()` is especially powerful, as it will return the *first non-NULL instance* it encounters in its arguments. This makes it possible to provide multiple fall-back options for NULL values.\n",
                "\n",
                "> Recall that we have already spent some time discussing how to deal with missing values in native Python data structures, such as by using [default dictionaries](https:\/\/docs.python.org\/3\/library\/collections.html#collections.defaultdict) and methods like [`dict.get()`](https:\/\/docs.python.org\/3\/library\/stdtypes.html#dict.get). Pandas has a [full section of documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/missing_data.html) dedicated to handling missing values.\n",
                "\n",
                "> You can see how SQLite handles operations with NULL values, alongside how other databases handle the same behavior, in their [documentation](https:\/\/www.sqlite.org\/nulls.html).\n",
                "\n",
                "> `ifnull(X, Y)` is functionally identical to `coalesce(X, Y)`. However, `coalesce()` can accept an arbitrary number of arguments greater than or equal to 2; `ifnull()`, by contrast, requires precisely 2.\n",
                "\n",
                "Consider the following example: we want to know what skills are required for each job posting contained in the `job_posting` table. We have two columns in the table which detail job requirements:\n",
                "\n",
                "1. `preferred_skills`, which gives us a precise description of what skills a desirable candidate will possess.\n",
                "2. `minimum_qual_requirements`, which provides a more general description of what is required for the position.\n",
                "\n",
                "The following query will attempt to display the preferred skills wherever possible. If they are not available, it will fall back to the minimum requirements. If neither are available, it will tell us that the requirements are unknown.\n",
                "\n",
                "```sql\n",
                "SELECT\n",
                "  job_id,\n",
                "  coalesce(\n",
                "    preferred_skills,\n",
                "    minimum_qual_requirements,\n",
                "    'UNKNOWN!'\n",
                "  ) AS job_requirements\n",
                "FROM job_posting\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "job_location_details.prompt"
                ]
            },
            "source": [
                "### Exercise 6: (0 points)\n",
                "**job_location_details**  \n",
                "\n",
                "**Your task:** define `job_location_details` as follows:\n",
                "\n",
                "**Activity**: Obtain details about each posting's location, using sensible defaults as defined below.\n",
                "\n",
                "**Inputs**: None\n",
                "\n",
                "**Return**: `query`: A Python string containing a SQLite query. It should query the database to create a new DataFrame from the `job_posting` and `location` tables with the following columns:\n",
                "- `job_id`: The id from the `job_posting` table.\n",
                "- `location`: The location of the posting, with null values replaced where necessary. It should be equal to:\n",
                "    - `work_location_1` in the `job_posting` table, if available.\n",
                "    - Otherwise, `location_name` in the `location` table, if available.\n",
                "    - Otherwise, set the value to the string, `UNKNOWN`.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- The query should join the `job_posting` and `location` tables with a left join to properly match the locations with the postings.\n",
                "- You can use either `IFNULL()` or `COALESCE()` to solve this problem.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "job_location_details.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 6  \n",
                "def job_location_details():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "job_location_details_query   = job_location_details()\n",
                "job_location_details_df      = pd.read_sql_query(job_location_details_query, conn)\n",
                "display(job_location_details_df.head(20))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "job_location_details.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output for the first ten rows:\n",
                "|    job_id | location                                              |\n",
                "|----------:|:------------------------------------------------------|\n",
                "|  556406_0 | 4 World Trade Center                                  |\n",
                "|  639388_1 | 75-20 Astoria Blvd                                    |\n",
                "|  642522_2 | 350 Jay St, Brooklyn Ny                               |\n",
                "|  627775_3 | 4 World Trade Center                                  |\n",
                "|  626542_4 | 470 Vanderbilt Ave                                    |\n",
                "|  631653_5 | 4WTC 150 Greenwich Street, 38th FL, New York NY 10007 |\n",
                "|  623231_6 | 150 William Street, New York NY                       |\n",
                "|  646189_7 | 55 Water St Ny Ny                                     |\n",
                "|  637846_8 | 42-09 28th Street                                     |\n",
                "|  645125_9 | 30-30 Thomson Ave L I City Qns                        |\n",
                "| 644065_10 | 4 World Trade Center                                  |\n",
                "| 642641_11 | 55 Water Street, NY, NY                               |\n",
                "| 637857_12 | 30-30 47TH AVE                                        |\n",
                "| 586802_13 | 59-17 Junction Blvd Corona Ny                         |\n",
                "| 632233_14 | 55 Water St Ny Ny                                     |\n",
                "| 593153_15 | 59-17 Junction Blvd Corona Ny                         |\n",
                "| 615463_16 | 4 World Trade Center                                  |\n",
                "| 643311_17 | 255 Greenwich Street                                  |\n",
                "| 616695_18 | 777 Third Avenue                                      |\n",
                "| 606905_19 | 520 1St Ave., N.Y.                                    |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for job_location_details (exercise 6). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_6",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "job_location_details.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 6  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.sql_executor(job_location_details),\n",
                "              ex_name='job_location_details',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to job_location_details did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rwVjgkDQLFiC"
            },
            "source": [
                "## Security Implications and Placeholder Bindings"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "7ecwb-FxLWWx"
            },
            "source": [
                "In part 0, we briefly alluded to this well-known [XKCD comic on SQL injection attacks](https:\/\/xkcd.com\/327\/). In this section, we'll explore the focus of this comic and why the implications are so important."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "oXqteRnqL4JJ"
            },
            "source": [
                "### Queries and User Input"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "NxHUT6vxMCOR",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "Imagine that we want to build a Python function which retrieves all of the job titles from our database belonging to a specific career-level. The career-level we are interested in could be any arbitrary value.\n",
                "\n",
                "You might realize that we can write a function which takes an argument, `level`, and define the function so that we can specify the career-level *when the function is called*.\n",
                "\n",
                "> Python has several different mechanisms for interpolating values into strings, such as [f-strings](https:\/\/docs.python.org\/3\/reference\/lexical_analysis.html#f-strings) and the [.format() method](https:\/\/docs.python.org\/3\/library\/stdtypes.html#str.format). Notice that we also define SQL queries as strings in Python. So, by using string interpolation, we can fill in the blanks of our query with whatever values we want!\n",
                "\n",
                "Let's try doing this by using string formatting. Then, we will show why this is a bad idea."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The function **get_jobs_by_level_dangerous** is simple enough. The caller gives the desired level and we use a format string to incorporate it directly into the SQL code.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_jobs_by_level_dangerous(level):\n",
                "    return f'SELECT * FROM job_title WHERE career_level = \"{level}\"'\n",
                "\n",
                "### Demo function call\n",
                "entry_level_query = get_jobs_by_level_dangerous('Entry-Level')\n",
                "pd.read_sql_query(entry_level_query, conn).head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XzeBE46ESVjM"
            },
            "source": [
                "### SQL Injection Attacks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "kcUEPYm3Sak9",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "So, why is this a bad idea?\n",
                "\n",
                "- Consider that we are defining our SQL queries by writing **text**. This text describes *code*, which tells the computer which instructions to execute.\n",
                "- However, we are describing variables in our query with **text**, too. Then, when we build the query, we are substituting part of our *code* with new *text*.\n",
                "\n",
                "So... what would happen if the *text* we substituted into our query **was valid SQL code?**\n",
                "\n",
                "The answer is that our query could potentially do almost *anything*. This is known as a [SQL Injection Attack](https:\/\/en.wikipedia.org\/wiki\/SQL_injection). Using string-formatting with Python to generate SQL queries does not protect against this.\n",
                "\n",
                "> This is not *necessarily* dangerous. For example, if you are the only person who will ever call this function, then there is no possibility that some user will intentionally try to abuse it. However, if you allow users to interact with this function (such as by collecting their inputs in a web-form), then this approach would let users execute nearly *any* SQL statement against your database.\n",
                "\n",
                "In this exercise, you will attempt to exploit this vulnerability and obtain more records than you might be expected to access."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "malicious_SQL_example.prompt"
                ]
            },
            "source": [
                "### Exercise 7: (0 points)\n",
                "**malicious_SQL_example**  \n",
                "\n",
                "**Your task:** define `malicious_SQL_example` as follows:\n",
                "\n",
                "**Activity**: Return a string value, which we will end up passing to `get_jobs_by_level_dangerous`. This string should be a value which will fetch *every* record from the `job_title` table.\n",
                "\n",
                "**Inputs**: `None`\n",
                "\n",
                "**Return**: `level`: a Python string which we will pass as the `level` argument to `get_jobs_by_level_dangerous`. The `level` string should be *purposefully malicious* and take advantage of SQL injection vulnerabilities, as outlined below.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- You may find the examples in Wikipedia's article on [Incorrectly Structured SQL Statements](https:\/\/en.wikipedia.org\/wiki\/SQL_injection#Technical_implementations) useful (*hint hint!*).\n",
                "- You should not be returning a full query. Only return the value for `level`, which we will use to build the full query.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "malicious_SQL_example.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 7  \n",
                "def malicious_SQL_example():\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "malicious_query = malicious_SQL_example()\n",
                "malicious_query = get_jobs_by_level_dangerous(malicious_query)\n",
                "print('Your malicious query:', malicious_query)\n",
                "malicious_query_df = pd.read_sql_query(malicious_query, conn)\n",
                "display(malicious_query_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "malicious_SQL_example.test_boilerplate"
                ]
            },
            "source": [
                " **Note**. This demo may not work correctly if you have not solved the previous exercise correctly. However, you can still pass the test cell with a proper solution, even if the demo below does not execute correctly.\n",
                "\n",
                "**Example**. A correct implementation should produce, for the demo, the following output for the first five rows:\n",
                "\n",
                "|   index |   id | business_title                          | civil_service_title            | title_code_no   | title_classification   | career_level              | job_category                                                                                                                          |\n",
                "|--------:|-----:|:----------------------------------------|:-------------------------------|:----------------|:-----------------------|:--------------------------|:--------------------------------------------------------------------------------------------------------------------------------------|\n",
                "|       0 |    1 | ADVISOR FOR STRATEGIC INITIATIVES       | ADMINISTRATIVE STAFF ANALYST ( | 1002D           | Competitive-1          | Experienced (non-manager) | Administration & Human Resources Constituent Services & Community Programs Communications & Intergovernmental Affairs Social Services |\n",
                "|       1 |    2 | Deputy Commissioner, Public Information | DEPUTY COMMISSIONER (DOC)      | 95043           | Non-Competitive-5      | Executive                 | Communications & Intergovernmental Affairs                                                                                            |\n",
                "|       2 |    3 | Media Services Aide                     | COMMUNITY ASSISTANT            | 56056           | Non-Competitive-5      | Entry-Level               | Administration & Human Resources Technology, Data & Innovation                                                                        |\n",
                "|       3 |    4 | DATA CONTROL SUPERVISOR                 | PRINCIPAL ADMINISTRATIVE ASSOC | 10124           | Competitive-1          | Entry-Level               | Administration & Human Resources Social Services                                                                                      |\n",
                "|       4 |    5 | UNIT CLERK                              | CLERICAL ASSOCIATE             | 10251           | Competitive-1          | Experienced (non-manager) | Administration & Human Resources Social Services                                                                                      |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for malicious_SQL_example (exercise 7). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_7",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "malicious_SQL_example.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 7  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.malicious_executor(malicious_SQL_example),\n",
                "              ex_name='malicious_SQL_example',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to malicious_SQL_example did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "bMO_IvQMcwhK"
            },
            "source": [
                "### Protecting Against SQL Injections"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "VTF0_pOLczp2",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "This is clearly a serious security concern! What can we do about it?\n",
                "\n",
                "> You should now have enough context to understand why this [XKCD comic](https:\/\/xkcd.com\/327\/) is both funny and insightful; the school-system did not know about injection attacks, and their **entire database was deleted** as a result.\n",
                "\n",
                "Instead of directly interpolating the values ourselves, we can ask the SQLite API to do it for us. All major Python-SQL interfaces will provide some mechanism for specifying placeholders in a query. Then, the SQL library will automatically escape special characters and keep your queries from executing unwanted code.\n",
                "\n",
                "In other words, instead of building the query *ourselves*, we will leave a placeholder in the query and give the SQL API a collection of values to interpolate. We will let the library take care of everything else.\n",
                "\n",
                "Python's [SQLite3 Module documentation](https:\/\/docs.python.org\/3\/library\/sqlite3.html#how-to-use-placeholders-to-bind-values-in-sql-queries) contains examples of how to do this. There are several approaches developers can use, but we will encourage the use of the `?` syntax here.\n",
                "\n",
                "> The exact method of doing this will vary by SQL backend, so always check the documentation to see how different engines require you to do this. For example, if you are using PostgreSQL, the [Psycopg documentation](https:\/\/www.psycopg.org\/psycopg3\/docs\/basic\/params.html) will tell you the specific syntax. Tools like [Pandas](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_sql.html) will often have a specific function argument for you to use, such as `params`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "get_jobs_by_level_safe.prompt"
                ]
            },
            "source": [
                "### Exercise 8: (0 points)\n",
                "**get_jobs_by_level_safe**  \n",
                "\n",
                "**Your task:** define `get_jobs_by_level_safe` as follows:\n",
                "\n",
                "**Activity**: Return a query which will select every record from the `job_title` table,\n",
                "  as long as the `career_level` column is equal to the value specified by `level`. Use placeholders\n",
                "  for the variable arguments and return the variables as a tuple.\n",
                "\n",
                "**Inputs**: `level`: A value for `career_level`, as a Python string. We will use it to decide which records to keep.\n",
                "\n",
                "**Return**: `output`: A tuple with two elements:\n",
                "- `jobs_by_level_safe_query`: A query, as a Python string, as defined above. Make sure you are using SQL placeholders!\n",
                "- `params`: A tuple with one element: `level`. We will use this to correctly bind the variables to the query.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- Make sure you are using placeholder syntax! You may find the documentation, linked above, useful!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "get_jobs_by_level_safe.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 8  \n",
                "def get_jobs_by_level_safe(level):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "query, params = get_jobs_by_level_safe('Entry-Level')\n",
                "get_jobs_by_level_safe_df = pd.read_sql_query(query, conn, params=params)\n",
                "display(get_jobs_by_level_safe_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "get_jobs_by_level_safe.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output for the first five rows:\n",
                "\n",
                "|   index |   id | business_title                                               | civil_service_title            |   title_code_no | title_classification   | career_level   | job_category                                                   |\n",
                "|--------:|-----:|:-------------------------------------------------------------|:-------------------------------|----------------:|:-----------------------|:---------------|:---------------------------------------------------------------|\n",
                "|       2 |    3 | Media Services Aide                                          | COMMUNITY ASSISTANT            |           56056 | Non-Competitive-5      | Entry-Level    | Administration & Human Resources Technology, Data & Innovation |\n",
                "|       3 |    4 | DATA CONTROL SUPERVISOR                                      | PRINCIPAL ADMINISTRATIVE ASSOC |           10124 | Competitive-1          | Entry-Level    | Administration & Human Resources Social Services               |\n",
                "|      15 |   16 | Claim Specialist                                             | CLAIM SPECIALIST               |           30726 | Competitive-1          | Entry-Level    | Legal Affairs                                                  |\n",
                "|      19 |   20 | City Mortuary Technician                                     | City Mortuary Technician       |           52020 | Labor-3                | Entry-Level    | Health                                                         |\n",
                "|      34 |   35 | Public Health Assistant (Part-Time), Bureau of School Health | PUBLIC HEALTH ASSISTANT (SCHOO |           81815 | Competitive-1          | Entry-Level    | Health                                                         |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for get_jobs_by_level_safe (exercise 8). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_8",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "get_jobs_by_level_safe.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 8  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.safe_executor(get_jobs_by_level_safe),\n",
                "              ex_name='get_jobs_by_level_safe',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to get_jobs_by_level_safe did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "tnOgMS7OgAd8",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "Congratulations! You should now understand one of the most common security vulnerabilities to consider when writing applications with SQL. Please remember to sanitize your user inputs when writing applications so that you don't fall victim to Bobby Tables!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "kqMAEiNDLBeT",
                "slideshow": {
                    "slide_type": ""
                },
                "tags": []
            },
            "source": [
                "## An Applied Example: Finding the Top N Cases per Group"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "lo35VZEMgf7T"
            },
            "source": [
                "In this section, you will use what you have learned to answer a commonly asked data analytics question: the \"top n-cases per group\" problem.\n",
                "\n",
                "To begin, consider a simple example. Imagine that we wanted to filter our records to keep only the top 200 job postings, ordered by their salary. At this point, we know we can accomplish this with the following keywords:\n",
                "\n",
                "- `ORDER BY`\n",
                "- `LIMIT`\n",
                "\n",
                "Now, consider a seemingly related problem: what if we want to keep the top 3 job postings by salary for *each group* of title classifications, as provided by the `job_title` table? Intuitively, you might recognize that you need to *partition* the table and rank the elements. We can do this with window functions. If we do this correctly, we can keep an arbitrary number of these records; we will generalize this by saying we want `n` records. You should recognize that this will mean we need to build the query with placeholder bindings. Finally, you may realize that you will need to filter the table based on the rankings: this means you will need to calculate the rankings *first* and then filter the table accordingly. This is a great indication that a CTE would make the query easier to write.\n",
                "\n",
                "In the exercise below, you will attempt to write a query like this."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "top_internal_postings_by_classification.prompt"
                ]
            },
            "source": [
                "### Exercise 9: (0 points)\n",
                "**top_internal_postings_by_classification**  \n",
                "\n",
                "**Your task:** define `top_internal_postings_by_classification` as follows:\n",
                "\n",
                "**Activity**: Get the Freshest, Highest Paying Job by Ranking and Filtering Internal Job Postings by Classification and Posting Date\n",
                "\n",
                "**Inputs**: `n`: The number of records to keep, per group.\n",
                "\n",
                "**Return**: \n",
                "- `query`: A Python string containing a SQLite query. It should query the database to create a new DataFrame from the `job_posting`, `job_title`, and `salary` tables with the following columns:\n",
                "    - `title_classification`: The job classification title from the `job_title` table.\n",
                "    - `business_title`: The business title of the job from the `job_title` table.\n",
                "    - `posting_updated`: The date when the job posting was last updated.\n",
                "    - `salary_range_to`: The maximum salary range for the job posting.\n",
                "    - `job_rank`: The rank of the job posting within its classification based on the `posting_updated` date, salary, and job ID.\n",
                "- `params`: A tuple containing `n`.\n",
                "\n",
                "**Requirements\/steps**:\n",
                "- Use a Common Table Expression (CTE) to rank job postings within each `title_classification` based on the `posting_updated` date, with ties broken by `salary_range_to` and `job_id` in that order. SQLite does not allow the direct use of window functions like `RANK()` in the `WHERE` clause. Therefore, a CTE is used to first calculate the ranks and the ranks are filtered in the outer query.\n",
                "- Use the `PARTITION BY` clause within the `RANK()` function to group the job postings by `title_classification` before ranking them, ensuring that the ranking is applied separately within each classification.\n",
                "- Filter the results to include only job postings where `posting_type` is `'Internal'`. This is necessary to avoid duplicates that occur when both internal and external versions of a job posting exist.\n",
                "- Return only the top 3 job postings per `title_classification`, ranked by their `posting_updated` date.\n",
                "- Order the final results by `title_classification` and the ranking.\n",
                "\n",
                "**Hint**: The following SQLite concepts and functions will help: [Common Table Expression (CTE)](https:\/\/www.sqlite.org\/lang_with.html) as well as `RANK` and `PARTITION BY` at the [SQLite Window Functions Page](https:\/\/www.sqlite.org\/windowfunctions.html).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "top_internal_postings_by_classification.solution"
                ]
            },
            "outputs": [],
            "source": [
                "### Solution - Exercise 9  \n",
                "def top_internal_postings_by_classification(n):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "\n",
                "### Demo function call\n",
                "top_internal_postings_by_classification_query, top_internal_postings_by_classification_params = top_internal_postings_by_classification(3)\n",
                "top_internal_postings_by_classification_df = pd.read_sql_query(top_internal_postings_by_classification_query, conn, params=top_internal_postings_by_classification_params)\n",
                "display(top_internal_postings_by_classification_df.head(20))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "top_internal_postings_by_classification.test_boilerplate"
                ]
            },
            "source": [
                " **Example**. A correct implementation should produce, for the demo, the following output:\n",
                "| title_classification     | business_title                                                                   | posting_updated         |   salary_range_to |   job_rank |\n",
                "|:-------------------------|:---------------------------------------------------------------------------------|:------------------------|------------------:|-----------:|\n",
                "| Competitive-1            | Traffic Analyst - OLS                                                            | 2024-08-26T00:00:00.000 |             96395 |          1 |\n",
                "| Competitive-1            | Childcare Inspection Supervisor                                                  | 2024-08-26T00:00:00.000 |             84616 |          2 |\n",
                "| Competitive-1            | Associate Project Manager                                                        | 2024-08-26T00:00:00.000 |             84401 |          3 |\n",
                "| Exempt-4                 | Assistant District Attorney Fall 2025                                            | 2024-08-21T00:00:00.000 |            100000 |          1 |\n",
                "| Exempt-4                 | Assistant District Attorney - Animal Cruelty Prosecution Initiative              | 2024-08-20T00:00:00.000 |            175000 |          2 |\n",
                "| Exempt-4                 | Assistant Corporation Counsel Mayor s Office of Special Enforcement              | 2024-08-15T00:00:00.000 |            212614 |          3 |\n",
                "| Labor-3                  | ELEVATOR DISPATCHER                                                              | 2024-08-23T00:00:00.000 |             50569 |          1 |\n",
                "| Labor-3                  | CARETAKER X                                                                      | 2024-08-19T00:00:00.000 |             50569 |          2 |\n",
                "| Labor-3                  | CARETAKER X                                                                      | 2024-08-19T00:00:00.000 |             50569 |          3 |\n",
                "| Non-Competitive-5        | General Counsel                                                                  | 2024-08-26T00:00:00.000 |            150000 |          1 |\n",
                "| Non-Competitive-5        | Senior Director of Research & Evaluation, Bureau of Brooklyn Neighborhood Health | 2024-08-26T00:00:00.000 |            136303 |          2 |\n",
                "| Non-Competitive-5        | Chief Employer Engagement Officer                                                | 2024-08-26T00:00:00.000 |            120000 |          3 |\n",
                "| Pending Classification-2 | Analyst FEMA Capital Budget Management                                           | 2024-08-22T00:00:00.000 |             74893 |          1 |\n",
                "| Pending Classification-2 | Receptionist                                                                     | 2024-08-22T00:00:00.000 |             71635 |          2 |\n",
                "| Pending Classification-2 | Chauffeur - Attendant                                                            | 2024-08-21T00:00:00.000 |             85000 |          3 |\n",
                "\n",
                " ---\n",
                " <!-- Test Cell Boilerplate -->  \n",
                "The cell below will test your solution for top_internal_postings_by_classification (exercise 9). The testing variables will be available for debugging under the following names in a dictionary format.  \n",
                "- `input_vars` - Input variables for your solution.   \n",
                "- `original_input_vars` - Copy of input variables from prior to running your solution. Any `key:value` pair in `original_input_vars` should also exist in `input_vars` - otherwise the inputs were modified by your solution.  \n",
                "- `returned_output_vars` - Outputs returned by your solution.  \n",
                "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "ex_9",
                    "locked": true,
                    "points": 0,
                    "solution": false
                },
                "tags": [
                    "top_internal_postings_by_classification.test"
                ],
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### Test Cell - Exercise 9  \n",
                "\n",
                "# Load testing utility\n",
                "with open('resource\/asnlib\/publicdata\/execute_tests', 'rb') as f:\n",
                "    execute_tests = dill.load(f)\n",
                "\n",
                "# Execute test\n",
                "passed, test_case_vars = execute_tests(func=plugins.safe_executor(top_internal_postings_by_classification),\n",
                "              ex_name='top_internal_postings_by_classification',\n",
                "              key=b'ml_6Ers6uRKDReNOadss3eZ9fueUNRX4IImbkbFoTRw=', \n",
                "              n_iter=100)\n",
                "# Assign test case vars for debugging\n",
                "input_vars, original_input_vars, returned_output_vars, true_output_vars = test_case_vars\n",
                "\n",
                "assert passed, 'The solution to top_internal_postings_by_classification did not pass the test.'\n",
                "\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n",
                "print('Passed! Please submit.')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}